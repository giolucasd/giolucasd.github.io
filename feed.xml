<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://giolucasd.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://giolucasd.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-08-01T20:32:32+00:00</updated><id>https://giolucasd.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple personal academic web page. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Notes on Image Classification</title><link href="https://giolucasd.github.io/blog/2023/image-classification/" rel="alternate" type="text/html" title="Notes on Image Classification"/><published>2023-07-14T00:00:00+00:00</published><updated>2023-07-14T00:00:00+00:00</updated><id>https://giolucasd.github.io/blog/2023/image-classification</id><content type="html" xml:base="https://giolucasd.github.io/blog/2023/image-classification/"><![CDATA[<h1 id="mia-3dcnn-covid-19-detection-based-on-a-3d-cnn">MIA-3DCNN: COVID-19 DETECTION BASED ON A 3D CNN</h1> <h2 id="1-authors">1. Authors</h2> <ul> <li>Igor Kenzo Ishikawa Oshiro Nakashima</li> <li>Giovanna Vendramini</li> <li>Helio Pedrini</li> </ul> <h2 id="2-abstract">2. Abstract</h2> <p>Early and accurate diagnosis of COVID-19 is essential to control the rapid spread of the pandemic and mitigate sequelae in the population. Current diagnostic methods, such as RT-PCR, are effective but require time to provide results and can quickly overwhelm clinics, requiring individual laboratory analysis. Automatic detection methods have the potential to significantly reduce diagnostic time. To this end, learning-based methods using lung imaging have been explored. Although they require specialized hardware, automatic evaluation methods can be performed simultaneously, making diagnosis faster. Convolutional neural networks have been widely used to detect pneumonia caused by COVID-19 in lung images. This work describes an architecture based on 3D convolutional neural networks for detecting COVID-19 in computed tomography images. Despite the challenging scenario present in the dataset, the results obtained with our architecture demonstrated to be quite promising.</p> <p>## 3. Notes</p> <p>## 3.1. I/O</p> <ul> <li>Input: 3D MRI image</li> <li>Output: <ul> <li>Covid detection (classification on positive or negative)</li> <li>Severity classification (classification on 4 classes of severity)</li> </ul> </li> </ul> <h3 id="32-data-preprocessing">3.2. Data preprocessing</h3> <p>Resizing with spline interpolation and data augmentation.</p> <h3 id="33-architecture">3.3. Architecture</h3> <p>Proposed architecture is a 3D CNN composed of two main stages, one composed of 3D convolutional blocks, and one composed of fully connected layers.</p> <p>Layers and parameters were decided upon experimentation.</p> <h3 id="34-questions">3.4. Questions</h3> <ul> <li> <p>How where the experiments for architecture definition done? Are they intuitivelly approachable? Does literature supports most of the decisions?</p> </li> <li> <p>Can data augmentation help prevent overfitting? If yes, why? Does it have a realtion with gaussian blur and noise?</p> </li> </ul> <h2 id="4-conclusions">4. Conclusions</h2> <p>The proposed architecture surpass baseline results for both tasks.</p>]]></content><author><name></name></author><category term="article"/><category term="machine learning"/><category term="computer vision"/><summary type="html"><![CDATA[MIA-3DCNN COVID-19 DETECTION BASED ON A 3D CNN]]></summary></entry><entry><title type="html">Notes on Semantic Segmentation</title><link href="https://giolucasd.github.io/blog/2023/sema-seg-ml/" rel="alternate" type="text/html" title="Notes on Semantic Segmentation"/><published>2023-07-13T00:00:00+00:00</published><updated>2023-07-13T00:00:00+00:00</updated><id>https://giolucasd.github.io/blog/2023/sema-seg-ml</id><content type="html" xml:base="https://giolucasd.github.io/blog/2023/sema-seg-ml/"><![CDATA[<h1 id="semantic-segmentation-of-volumetric-medical-images-with-3d-convolutional-neural-networks">Semantic Segmentation of Volumetric Medical Images with 3D Convolutional Neural Networks</h1> <h2 id="1-authors">1. Authors</h2> <ul> <li>Alejandra M´arquez Herrera (alejandra.marquez@ucsp.edu.pe)</li> <li>Alex Jesus Cuadros-Vargas (alex@ucsp.pe)</li> <li>Helio Pedrini (helio@ic.unicamp.br)</li> </ul> <h2 id="2-abstract">2. Abstract</h2> <p>A neural network is a mathematical model that is able to perform a task automatically or semi-automatically after learning the human knowledge that we provided. Moreover, a Convolutional Neural Network (CNN) is a type of neural network that has shown to efficiently learn tasks related to the area of image analysis, such as image segmentation, whose main purpose is to find regions or separable objects within an image. A more specific type of segmentation, called semantic segmentation, guarantees that each region has a semantic meaning by giving it a label or class. Since CNNs can automate the task of image semantic segmentation, they have been very useful for the medical area, applying them to the segmentation of organs or abnormalities (tumors). This work aims to improve the task of binary semantic segmentation of volumetric medical images acquired by Magnetic Resonance Imaging (MRI) using a pre-existing Three-Dimensional Convolutional Neural Network (3D CNN) architecture. We propose a formulation of a loss function for training this 3D CNN, for improving pixel-wise segmentation results. This loss function is formulated based on the idea of adapting a similarity coefficient, used for measuring the spatial overlap between the prediction and ground truth, and then using it to train the network. As contribution, the developed approach achieved good performance in a context where the pixel classes are imbalanced. We show how the choice of the loss function for training can affect the final quality of the segmentation. We validate our proposal over two medical image semantic segmentation datasets and show comparisons in performance between the proposed loss function and other pre-existing loss functions used for binary semantic segmentation.</p> <h2 id="3-notes">3. Notes</h2> <h3 id="31-io">3.1. I/O</h3> <ul> <li>Input: 3D MRI image</li> <li>Output: Pixel classification over 3D image</li> </ul> <h3 id="32-data-preprocessing">3.2. Data preprocessing</h3> <p>Resizing, normalization and data augmentation.</p> <h3 id="33-loss-function">3.3. Loss function</h3> <p>Common losses for classification are accuracy, precision, recall and F1. Neither have good performance on imbalanced data. MMC and AUC can put up a good fight, but MMC seems convenient since it can measure spacial overlap on images.</p> <h3 id="34-experiments">3.4 Experiments</h3> <ul> <li>NN: Dense V-Net (beat up V-Net, VoxResNet and a MALF-based method)</li> <li>Datasets: <ul> <li>PROMISE12 Prostate Dataset (50 samples)</li> <li>BRATS15 Brain Tumor Dataset (271 samples)</li> </ul> </li> <li>Compared losses: <ul> <li>cross-entropy loss</li> <li>Dice loss</li> <li>Generalized Wasserstein Dice loss</li> </ul> </li> <li>Validation: <ul> <li>Dice score</li> <li>70% training, 20% validation, and 10% inference</li> <li>Train from scrath</li> </ul> </li> <li>Results: <ul> <li>MMC seems very solid in comparison with other losses, reaching good performances early and mantaining overall best results.</li> </ul> </li> </ul> <h3 id="34-questions">3.4 Questions</h3> <ul> <li>Wouldn’t it be more appropriate to evaluate using cross-valdation given such a small dataset size?</li> <li>Would train the models on both datasets (obviously resizing and normalizing data) help or harm the models learning? The problems seems quite correlated to me and I’m not sure specializing is necessarily better.</li> </ul> <h2 id="4-conclusions">4. Conclusions</h2> <ul> <li>More data and better fitted model for the specific problems could help good performance and better evaluation.</li> <li>It might be a good idea to derive loss function from a correlation coefficient.</li> <li>Better analysis could be done for bigger batch sizes, but computational power didn’t allow it.</li> <li>Proposed loss is actually good.</li> </ul>]]></content><author><name></name></author><category term="article"/><category term="machine learning"/><category term="computer vision"/><summary type="html"><![CDATA[Semantic Segmentation of Volumetric Medical Images with 3D Convolutional Neural Networks]]></summary></entry></feed>